{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5476ad8-91f9-4e5b-adbf-2598e96f3c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 6 rows for departments in 0.02s (267 rows/sec)\n",
      "Done\n",
      "✅ Processed 58 rows for categories in 0.01s (10357 rows/sec)\n",
      "Done\n",
      "❌ Error processing products: value too long for type character varying(45)\n",
      "CONTEXT:  COPY temp_products_1746618410, line 34, column product_name: \"\"Nike Women's Pro Core 3\"\" Compression Shorts\"\"\n",
      "\n"
     ]
    },
    {
     "ename": "StringDataRightTruncation",
     "evalue": "value too long for type character varying(45)\nCONTEXT:  COPY temp_products_1746618410, line 34, column product_name: \"\"Nike Women's Pro Core 3\"\" Compression Shorts\"\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStringDataRightTruncation\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables:\n\u001b[1;32m     11\u001b[0m     df \u001b[39m=\u001b[39m read_table_as_df(base_dir, table)\n\u001b[0;32m---> 12\u001b[0m     upsert_to_postgres(df, table, engine, unique_columns\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/de_on_gcp/Data_Engineering_GCP/PreReqs/db_writer.py:98\u001b[0m, in \u001b[0;36mupsert_to_postgres\u001b[0;34m(df, table_name, engine, unique_columns)\u001b[0m\n\u001b[1;32m     95\u001b[0m cursor \u001b[39m=\u001b[39m raw_conn\u001b[39m.\u001b[39mcursor()\n\u001b[1;32m     97\u001b[0m \u001b[39m# Use native PostgreSQL COPY for fastest bulk insert to temp table\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m cursor\u001b[39m.\u001b[39;49mcopy_from(buffer, temp_table_name, columns\u001b[39m=\u001b[39;49mdf\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mtolist(), null\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mN\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    100\u001b[0m \u001b[39m# Generate column lists for the SQL command\u001b[39;00m\n\u001b[1;32m    101\u001b[0m all_columns \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(df\u001b[39m.\u001b[39mcolumns)\n",
      "\u001b[0;31mStringDataRightTruncation\u001b[0m: value too long for type character varying(45)\nCONTEXT:  COPY temp_products_1746618410, line 34, column product_name: \"\"Nike Women's Pro Core 3\"\" Compression Shorts\"\"\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "from file_reader import read_table_as_df\n",
    "from db_writer import get_engine, upsert_to_postgres\n",
    "\n",
    "base_dir = '/Users/kshitijmac/Documents/Data_Files/retail_db'\n",
    "tables = ['departments', 'categories', 'products', 'customers', 'orders', 'order_items']\n",
    "\n",
    "engine = get_engine()\n",
    "\n",
    "for table in tables:\n",
    "    df = read_table_as_df(base_dir, table)\n",
    "    upsert_to_postgres(df, table, engine, unique_columns=None)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ed3ff-e481-4b8a-80e1-d2be51a88ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 6 rows for departments in 0.02s (249 rows/sec)\n",
      "Done\n",
      "✅ Processed 58 rows for categories in 0.01s (4783 rows/sec)\n",
      "Done\n",
      "✅ Processed 1345 rows for products in 0.02s (57457 rows/sec)\n",
      "Done\n",
      "✅ Processed 12435 rows for customers in 0.10s (124518 rows/sec)\n",
      "Done\n",
      "✅ Processed 68883 rows for orders in 0.38s (180314 rows/sec)\n",
      "Done\n",
      "✅ Processed 172198 rows for order_items in 0.76s (227338 rows/sec)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "from file_reader import read_table_as_df\n",
    "from db_writer import get_engine, upsert_to_postgres\n",
    "\n",
    "base_dir = '/Users/kshitijmac/Documents/Data_Files/retail_db'\n",
    "tables = ['departments', 'categories', 'products', 'customers', 'orders', 'order_items']\n",
    "\n",
    "engine = get_engine()\n",
    "\n",
    "for table in tables:\n",
    "    df = read_table_as_df(base_dir, table)\n",
    "    upsert_to_postgres(df, table, engine, unique_columns=None)\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
